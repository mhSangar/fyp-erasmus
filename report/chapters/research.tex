\chapter{Research}
\label{research}

%\section{Introduction to Machine Learning}			
%\section{Artificial Neural Networks}				
%\section{The Perceptron}
%	\subsection{Linearly Separable attribute}		** (img)
%	\subsection{Training Rule}
%	\subsection{Delta Rule and Gradient Descent}
%	\subsection{Derivation of Gradient Descent}
%	\subsection{Gradient Descent Algorithm}
%	\subsection{Stochastic Approximation}
%\section{Multilayer Perceptron Networks}
%	\subsection{Is a perceptron valid for MLP? The Sigmoid Unit}
%	\subsection{Backpropagation Algorithm}
%\section{ANNs vs CNNs} 					% **
%\section{Face Recognition using CNNs}		% disabled for now
%\section{Public Data Sets}
%\section{Raspberry Pi}											*new*
%	\subsection{Using the Pi-camera}							*new*
%\section{Python}

\section{Introduction}
In this section we are going to explain the state of the art of the different fields related to the project, along with some of the technologies that were used in its development (i.e. Raspberry Pi, Python). It starts with a brief introduction to \gls{ml}, followed by an explanation of different neural networks heavily based on the books from \cite{mitchell1997} and \cite{haykin2009neural}. In the case of \glspl{cnn}, it is also included how they are applied for face recognition. Different approaches for face detection can be found in the following section, along with the usual limitations of these techniques. It finishes with little sections about the Raspberry Pi and Python. 


\section{Machine Learning}
Ever since computers were invented, we have wondered whether they might be able to learn. If we could understand how to program them to learn, improving automatically with experience, the impact would be dramatic. Althought we do not know yet how to make computers learn nearly as well as people do, several algorithms have been invented that are effective for certain types of learning tasks (\cite{mitchell1997}).  

"Machine learning" was coined by \cite{ml_first_def}, an American pioneer in the field of computer gaming and \gls{ai}. He defined it as "the field of study that gives computer the ability to learn without being explicitly programmed". Time has passed since then, so a more updated definition of Machine Learning could be "a set of methods that can automatically detect patterns in data, and then use the uncovered patterns to predict future
data, or to perform other kinds of decision making under uncertainty" (\cite{kevin_p_murphy_book}).

Recent \gls{ml} implementations do not have to make us think that \gls{ml} has been being just theorical until now. An early application of machine learning was ELIZA (\cite{eliza_machine}), a natural language processing program able to read messages typed on a typewriter and respond by writing on the same instrument. Using pattern matching, it was capable of simulate a conversation and give users the illusion of being understood by the program.  

The technology needed to compute \gls{ml} algorithms was a prohibitive factor for a long time, but nowadays anyone can rent a really expensive GPU cluster for a few dollars an hour, something that PhD students dreamed about just 10 years ago (\cite{pyhton_n_intro_to_ML}). Nevertheless, besides the more powerful computing power, what actually made \gls{ml} to rise in the recent years was the release of easily readable APIs (e.g. \cite{tensorflow_main_website}) and the advent of cloud computing, that made \gls{ml} accessible to the big public.

Within machine learning, we can find three different approaches (\cite{kevin_p_murphy_book}):
\begin{itemize}
	\item Supervised learning. Its goal is to learn a mapping from inputs $x$ to outputs $y$, given a labelled set of input-output pairs $D={(x_i ,y_i)}^N$, called training set. Each training input $x_i$ is a $D$-dimensional vector of numbers, which can represent from simple a height value to complex structured object, such as images. Similarly, the form of the output can in principle be anything, but most methods assume that $y_i$ is a categorical or nominal value from a finite set (e.g. male, female), making the problem to be called \textit{pattern recognition}, or an scalar (e.g. distance), making the problem to be called \textit{regression} instead.  

	\item Unsupervised learning. Here we are only given inputs, $D={x_i}^N$, and the goal is to find “interesting patterns” in the data. It is a much less well-defined problem, since we are not told what kinds of patterns to look for, and there is no obvious error metric because, unlike supervised learning, it is not possible to compare the expected output to the observed value. 

	\item Reinforcement learning. Less commonly than the other two, it learns how to act or behave when given occasional reward or punishment signals. For example, the way dogs are trained to piss out of the house would be a great example of the application of this learning approach.  
\end{itemize}


% █████╗ ███╗   ██╗███╗   ██╗    ███████╗
%██╔══██╗████╗  ██║████╗  ██║    ██╔════╝
%███████║██╔██╗ ██║██╔██╗ ██║    ███████╗
%██╔══██║██║╚██╗██║██║╚██╗██║    ╚════██║
%██║  ██║██║ ╚████║██║ ╚████║    ███████║
%╚═╝  ╚═╝╚═╝  ╚═══╝╚═╝  ╚═══╝    ╚══════╝
                                        

\section{Artificial Neural Networks}
\glspl{ann} have generated a lot of excitement in \gls{ml} research and industry, thanks to many breakthrough results in speech recognition, computer vision and text processing (\cite{intro_ann}). 

It is apparent that a neural network derives its computing power through, first, its massively parallel distributed structure of simple computing cells (i.e. neurons) and, second, its ability to learn and therefore generalize (i.e. product reasonable outputs for inputs not encountered during training). These last two capabilities make \glspl{ann} a good approximate solution for intractable problems, such as the previously mentioned speech and image recognition.

In the Figure \ref{fig:org_neuron} we can see the model of the organic mutual of the neurons used in an \gls{ann}. Organic neurons interact with each others using synapses, which are constituted by axon terminals, the transmission lines, and dendrites (so called because of its resemblance to a tree), the receptive zones. The artificial neurons we use to build our neural networks are truly primitive in comparison with those found in the brain, but there is still a ressemblance between them.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=10cm]{bio-neuron.jpg}
	\caption{Organic Neuron model}
	\label{fig:org_neuron}
\end{figure}

The \glspl{ann} design is actually motivated by analogy with the brain, which is the living proof that fault-tolerant parallel processing is not only physically possible, but also fast and powerful. While neurobiologists look to \glspl{ann} as a research tool for to interpretate the neurobiological phenomena (\cite{anastasio1993}), engineers look to neurobiology for new ideas to solve more complex problems (\cite{mead1989}).

%Now going back to our artificial neural networks, we can see how the model of one of its units is pretty similar (\textit{Figure ~\ref{fig:art_neuron}}). In first place, the unit receives inputs ($x_i$) from an external source or from other units. Each of these inputs have an associated weight ($w_i$), assigned depending of its relative importance to the other inputs. After the unit applies a function $f$ to the weighted sum of its inputs, and finally it gives an output.

%Construct a network is as simple as connecting inputs to outputs, but to construct a feedforward network. This network is divided in layers, so nodes from the same layer are not connected and between adjacent layers each connection has associated a weight. 

%%%%%%%%%%%%% CHANGE IMAGE %%%%%%%%%%%%%
%\begin{figure}[ht]
%	\centering
%	\includegraphics[width=\textwidth]{ann_basic_model.jpg}
%	\caption{Basic Artificial Neural Network}
%\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Because of the position of these nodes and the connections between them we can differentiate three types of nodes: input, hidden and output nodes.

%\begin{itemize}
%	\item Input Nodes: provide information from the outside world without computing anything, they just past the information to the hidden nodes. Collectively the nodes in this layer are referred to as the \textit{Input Layer}. 
%	\item Hidden Nodes: they have no connection with the outside world (hence the name "hidden"), but they compute the information provided from the previous layer and give the output to the next one. Collectively the nodes in this layer are referred to as the \textit{Hidden Layer}. Although articial neural networks must have only one input layer and one output layer, they can have more than one hidden layer (or none). 
%	\item Output Nodes: collectively the nodes in this layer are referred to as the \textit{Output Layer} and they are responsible to transfer the computed information to the outside world again.
%\end{itemize}



%██████╗ ███████╗██████╗  ██████╗███████╗██████╗ ████████╗██████╗  ██████╗ ███╗   ██╗
%██╔══██╗██╔════╝██╔══██╗██╔════╝██╔════╝██╔══██╗╚══██╔══╝██╔══██╗██╔═══██╗████╗  ██║
%██████╔╝█████╗  ██████╔╝██║     █████╗  ██████╔╝   ██║   ██████╔╝██║   ██║██╔██╗ ██║
%██╔═══╝ ██╔══╝  ██╔══██╗██║     ██╔══╝  ██╔═══╝    ██║   ██╔══██╗██║   ██║██║╚██╗██║
%██║     ███████╗██║  ██║╚██████╗███████╗██║        ██║   ██║  ██║╚██████╔╝██║ ╚████║
%╚═╝     ╚══════╝╚═╝  ╚═╝ ╚═════╝╚══════╝╚═╝        ╚═╝   ╚═╝  ╚═╝ ╚═════╝ ╚═╝  ╚═══╝
                                                                                    


\section{The perceptron}
\label{sec:perceptron}
Within \glspl{ann}, we can find great variety of neurons, among which perceptrons occupy a special place in the historical development of neural networks, being the first algorithmically described. Invented by \cite{rosenblatt1958perceptron}, it is built around a nonlinear neuron model (Figure \ref{fig:nonlinear_neuron_model}) named McCulloch-Pitts, which is composed of:

\begin{figure}[!ht]
	\centering
	\includegraphics[width=10cm]{ann_neuron_haykin}
	\caption{Nonlinear model of a neuron (\cite{haykin2009neural})}
	\label{fig:nonlinear_neuron_model}
\end{figure}

\begin{itemize}
	\item Synapses or inputs ($x_i$). Connecting links that obtain stimulus from an external source. A signal $x_i$ at the input of synapse $i$, connected to the neuron $k$, has an associated weight $w_ki$ for what it will be multiplied by. This weight may lie in a range that includes positives and negatives values.

	\item Adder ($\sum$, \textit{summing junction} in the Figure). It sums the weighted input signals in an operation called linear combination, adding at the end an externally applied bias $b_k$ (\ref{eq:linear_combination}):

	\begin{equation}
	    \label{eq:linear_combination}
	        v_k=\sum_{i=1}^{m} w_{ki} x_i + b_k = w_{k1} x_1 + w_{k2} x_2 + w_{k3} x_3 + ... + b_k%
	\end{equation}

	\item Activation function ($\varphi$). It limits the amplitude of the output of the neuron by the following expression (\ref{eq:perceptron_rule}), known as threshold function. This expression makes the perceptron to have only two different outputs or classes. 

	\begin{equation}
	    \label{eq:perceptron_rule}
			y_k =
				\begin{cases}
			     	1 & \text{if } v_k > 0 \\
			        -1 & \text{otherwise} \\
				\end{cases}
		\end{equation}
	\end{itemize}

	\subsection{Linearly Separable attribute}
	For the perceptron to function properly, the two classes ($C_0$,$C_1$) must be \textit{linearly separable}. This, in turn, means that the patterns to be classified must be sufficiently separated from each other to ensure that the decision surface consists of a hyperplane.

	We are going to explain it with an example, using a percetron with two inputs (i.e. 2 dimensions). The use of a single neuron with two inputs results in a straight line (i.e. hyperplane) for a decision boundary in the input space (Figure \ref{fig:linear_sep_xor}, (a)). For all points on one side of this line, the perceptron outputs $+1$; for all points on the other side of the line, it outputs $-1$.

	\begin{figure}[!ht]
		\centering
		\includegraphics[width=10cm]{linearly_sep_xor}
		\caption{Linear separation problem of the XOR operation (\cite{mitchell1997})}
		\label{fig:linear_sep_xor}
	\end{figure}

	However, nonlinearly separable patterns commonly occur, like in the known \textit{exclusive-OR problem} or simply \textit{XOR problem}. We need to consider the four corners of a square centered in (0,0) that correspond to the input patterns (1,1), (1,-1), (-1,-1) and (-1,1) (Figure \ref{fig:linear_sep_xor}, (b)). With the top-left and bottom-right input patterns belonging to one class and the top-right and bottom-left belonging to the other class (Equation \ref{eq:xor_problem}), it is clear that we cannot construct a straight line for a decision boundary so the ($+$) class lie in one decision region and the ($-$) class lie in the other decision region. In other words, \textit{a single perceptron cannot solve the XOR problem} because \textit{the inputs are not linearly separable}.

	\begin{equation}
		\label{eq:xor_problem}
	    \begin{aligned}
	        (\hspace{0.78em} 1,\hspace{0.78em} 1) \quad \rightarrow \quad  \hspace{0.78em} 1 \oplus \hspace{0.78em} 1 = 0 \quad \rightarrow \quad C_0(-) \\[5pt]
	        (\hspace{0.78em} 1,-1) \quad \rightarrow \quad  \hspace{0.78em} 1 \oplus -1 = 1 \quad \rightarrow \quad C_1(+) \\[5pt]
	        (-1,-1) \quad \rightarrow \quad -1 \oplus -1 = 0 \quad \rightarrow \quad C_0(-) \\[5pt]
	        (-1, \hspace{0.78em} 1) \quad \rightarrow \quad -1 \oplus \hspace{0.78em} 1 = 1 \quad \rightarrow \quad C_1(+) \\[15pt]
	    \end{aligned}
	\end{equation}

	\subsection{Training Rule}
	In order to train perceptrons, we begin assigning random values to the weights to then apply the perceptron to each training example. If the perceptron misclassifies an example, the training rule will modify the weights $w_i$ according to:

	\begin{equation}
		\label{training_rule}
		w_{i}^{'} \leftarrow w_{i} + \eta (t - o) x_{i}
	\end{equation}

	where $\eta$ is the \textit{learning rate} (constant usually small that determines how much weights vary in each step), $t$ is the target value, $o$ is the actual output that we have obtained from the perceptron and $x_{i}$ is the input value. The weights will converge to a value that classify correctly within a finite number of iterations \textit{if (and only if) examples are linearly separable} and the $\eta$ value used is sufficiently small.
	
	\subsection{Delta Rule and Gradient Descent}
	When the input set is not linearly separable, we need an alternative to the training rule: the delta rule. Delta rule uses gradient descent to search for the set of outputs (i.e. hypothesis space) that fit best the training example. 

	To explain this we are going to use a linear unit that, unlike the perceptron, is not thresholded. Its output is calculated by $o = \vec{w} \cdot \vec{x}$. To measure the training error we are going to use the following formula (Equation \ref{error_function_full_square}), where $D$ is the set of examples. We assume that the relation with the example set $\vec{x}$ will be gone after the training, so the error depends only of $\vec{w}$.

	\begin{equation}
		\label{error_function_full_square}
		E(\vec{w}) = \frac{1}{2} \sum_{d \varepsilon D} (t_d-o_d)^2 
	\end{equation}

	When the error is defined by this formula, its visual representation refers to a parabolic surface with only one local minimum (Figure \ref{fig:parabolic_surf}). We can imagine that the current error value is a small ball located inside this bowl-like parabolic surface. The gradient descent will start using a random initial vector, so the ball will be located in a random point of the surface. The algorithm will move this ball like the gravity would do, modifying its direction step by step by choosing the variation that go the deepest along the error surface. The process will continue until the ball reaches the bottom of the bowl, or formally, until the error reaches the local and global minimum.

	\begin{figure}[!ht]
		\centering
		\vspace{0.5cm}
		\includegraphics[width=9cm]{parabolic_surface.jpg}
		\caption{Parabolic Surface with one local minimum}
		\label{fig:parabolic_surf}
	\end{figure}

	\subsection{Derivation of Gradient Descent}
	To modify the direction of the vector we will derivate the error function ($E(\vec{w})$) respect of $\vec{w}$, obtaining the \textit{gradient of E}:

	\begin{equation}
		\label{gradient_of_E}
		\nabla E(\vec{w})= [\frac{\partial{E}}{\partial{w_{0}}}, \frac{\partial{E}}{\partial{w_{1}}}, ..., \frac{\partial{E}}{\partial{w_{n}}}]
	\end{equation}

	This vector specifies the direction that produces the steepest \textit{increase} in E, so to calculate the steepest \textit{decrease} in E, a negative factor ($-1$) is included. We can represent the training rule with its component form:

	\begin{equation}
		\label{training_rule_component_form}
		w_{i}^{'} \leftarrow w_{i} + \Delta w_{i} \qquad ; \qquad \Delta{w_{i}}=-\eta \frac{\partial{E}}{\partial{w_i}}
	\end{equation}

	So the final expression of the gradient descent is:

	\begin{equation}
		\label{gradient_descent_final_expr}
		\Delta w_i = -\eta \frac{\partial{E}}{\partial{w_i}} = \eta \sum_{d \varepsilon D} (t_d - o_d) x_{id}
	\end{equation}

	The Gradient Descent algorithm would start then with a random weight vector. It will apply the linear unit to all the training examples and then compute $\Delta w_i$ using the gradient descent formula (Equation \ref{gradient_descent_final_expr}). The weights are updated with the calculated value $\Delta{w_{i}}$ (Equation \ref{training_rule_component_form}). Finally, if the local minimum is reached, it stops. If not, the linear unit is applied to all the training examples and the process is repeated from that point, but using the weights from the previous step.

	\subsection{Stochastic Approximation}
	Using all the examples in each step to update the weights may imply a lot of computing work. Another approach is the incremental or stochastic gradient descent, where the gradient descent is just approximated, updating the weights with each training example (Equation \ref{delta_rule}). From a practical perspective, some accuracy is sacrificed in order to make the algorithm much faster.

	\begin{equation}
		\label{delta_rule}
		\Delta w_{i}= \eta (t - o) x_{i}
	\end{equation}

	The error function also changes with this approach, being now:

	\begin{equation}
		\label{error_function_stoc_square}
		E(\vec{w}) = \frac{1}{2} (t_d-o_d)^2 
	\end{equation}


%███╗   ███╗██╗     ██████╗ 
%████╗ ████║██║     ██╔══██╗
%██╔████╔██║██║     ██████╔╝
%██║╚██╔╝██║██║     ██╔═══╝ 
%██║ ╚═╝ ██║███████╗██║     
%╚═╝     ╚═╝╚══════╝╚═╝     
                           

\section{Multilayer Perceptron Networks}
In the section \ref{sec:perceptron}, we explained Rosenblatt’s perceptron, which is basically a single-layer neural network. Therein, we showed that how it is limited to the classification of linearly separable patterns. To overcome the practical limitations of the perceptron, we look to the \glspl{mlp}. The Figure \ref{fig:mlp_architectural_graph} shows the architectural graph of a fully-connected \gls{mlp}. The perceptrons are organised in layers (i.e. input layer, hidden layers and ouput layer), so the signal flow through the network progresses in a forward direction.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=12cm]{multilayer_network}
	\caption{Architectural graph of a multilayer perceptron with two hidden layers (\cite{haykin2009neural})}
	\label{fig:mlp_architectural_graph}
\end{figure}

The hidden layers act as feature detectors and, as such, play a critical role in the operation of a \gls{mlp}. When the networks starts the learning process, the hidden neurons begin to gradually “discover” the salient features that characterize the training data. They do so by performing a nonlinear transformation on
the input data into a new space called the feature space. The formation of this feature space through supervised learning is what distinguishes \glspl{mlp} from the Rosenblatt’s perceptron.

	\subsection{Is a perceptron valid for MLP? The Sigmoid Unit}
	A perceptron, as nonlinear neuron model, is perfectly valid for a \gls{mlp}. However, the discontinuous threshold output of the perceptron make it undifferentiable and hence not suitable for gradient descent (Figure \ref{fig:threshold_vs_sigmoid}). What we need is a unit whose output is a nonlinear function of its inputs, but whose output is a differentiable function of its inputs. One solution is the \textit{sigmoid unit}, a unit very similar to the perceptron, but based on a smoothed, differentiable threshold function called logistic or \textit{sigmoid function} ($\sigma(y)$).

		\begin{equation}
			\label{sigmoid_function}
			\sigma(y) = \frac{1}{1+e^{-y}}
		\end{equation}


	\begin{figure}[!ht]
		\centering
		\vspace{0.3cm}
		\includegraphics[width=7cm]{threshold_vs_sigmoid}
		\caption{Activation functions of a neuron (\cite{haykin2009neural}). \\(a) Threshold function. \\(b) Sigmoid funtion.}
		\label{fig:threshold_vs_sigmoid}
	\end{figure}

	The sigmoid function increases monotonically and continuously with its input (Figure \ref{fig:threshold_vs_sigmoid}). Because it is able to map a large input domain to a small range (0, 1) of outputs, it is usually referred as \textit{squashing function}. It also has the useful property of being easy derivable in terms of its output, which will be taken advantage of calculating the gradient descent learning rule.

	\subsection{Backpropagation Algorithm}
	Back Propagation is a specific technique for implementing gradient descent in the weight space for a \glspl{mlp}. The gradient descent now minimize a different function to the defined previously in the Equation \ref{error_function_full_square} for the perceptron: 

		\begin{equation}
			\label{squared_error_function_network}
			E(\vec{w}) = \frac{1}{2} \sum_{d \varepsilon D} \sum_{k \varepsilon outputs} (t_{kd}-o_{kd})^2 
		\end{equation}

	As we have changed the error function definition, the error surface has changed too, having now more than one local minimum. This means that gradient descent may fail in order to find the global minimum and only reach local minima instead. Following with the metaphor of the error value and the small ball, the error surface could now be a golf terrain with many holes. The gradient descent will try to move the ball inside one of these holes (i.e. local minima), but it has no way to know whether that hole is the deepest of the field (i.e. global minima). 

	Despite this obstacle, in practice the backpropagation algorithm has been found to produce excellent results in many real-world applications. It is also interesting to see that some of the variations of this algorithm are actually based in the physics of treating the error value as a ball. One example is including momentum in the gradient descent, so the "ball" tends to keep rolling in the same direction from one iteration to the next one.

	As seen previously in the perceptron section, the gradient descent has an incremental or stochastic version, where the weights are computed for each training example. A brief explanation of the stochastic version of the backpropagation algorithm would be:

		\begin{enumerate}
			\item Input the values in the network and obtain the output values computing every unit of the network.
			\item For each output unit ($k$), calculate its error term $\delta_k$, which is the usual $(t-o)$ multipied to the derivate of the sigmoid function:
				\begin{equation}
					\label{backpropagation_output_error}
					\delta_k \leftarrow o_k (1 - o_k)(t_k - o_k)
				\end{equation}				

			\item For each hidden unit ($h$), calculate its error term $\delta_h$. This is similar to the output formula, but as we don't have a target value for a hidden unit, we must calculate it summing up the errors of the downstream units weigthing each error by the weight of the connection that links them. 
				\begin{equation}
					\label{backpropagation_hidden_error}
					\delta_h \leftarrow o_h (1 - o_h) \sum_{l \varepsilon downstream} (w_{hl} \delta_i)
				\end{equation}

			\item Update each network weight:
				\begin{equation}
					\label{backpropagation_weight_update}
					w^{'}_{ji} \leftarrow w_{ji} + \Delta w_{ji} \hspace{1.5cm} ; \hspace{1.5cm} \Delta w_{ji} = \eta \delta_j x_{ji}
				\end{equation}
		\end{enumerate} 


\section{Convolutional Neural Networks and Face Recognition}
The Artificial Neural Networks (\glspl{ann}) we have seen until now have their applications, but the current state of the art for detecting what an image is (or what does it contains) are Convolutional Neural Networks (\glspl{cnn}). First of all we need to explain that this two kinds of neural networks are not at the same level. The \glspl{ann} we have seen until now usually have a few hidden layers, but \glspl{cnn} need to have multiple of these hidden layers in order to achieve what is known as Deep Learning. 

It may seem normal that adding more hidden layers to a network will improve its learning potential, but the problem with deep networks is that it becomes harder to learn the weights as the network becomes "deeper". In \cite{huang2016deep}, they mentioned this problem as \textit{Diminishing Feature Reuse} or \textit{Loss in the Information Flow}, explaining that the features of the input instance (or those computed by previous layers) are "washed out" in the proccess of learning, which makes it hard for later layers to learn meaningful gradient directions. Since the weights in the network are randomly initialised, it can become pretty hard (even impossible) to achieve learning in a deep neural network using backpropagation. Here is where Deep Learning comes into play, providing algorithms and architectures that helps in the training of such deep neural networks. 

Convolutional Neural Networks are one of the options Deep Learning provides. As \cite{lecun2015deep} explain, they are designed to proccess data that comes in the form of multiple arrays, which suits perfectly to our needs to work with images. For example, a colour image could be decomposed in three two-dimensions arrays that contain the pixel intensities in the three colour channel of RGB. 

%%% maybe include something from lecun paper, first page %%%

In terms of architecture, \glspl{cnn} are structured as a series of stages. First few stages are composed by convolutional and pooling layers (\cite{lecun2015deep}). 

Pooling is simple, it is just a down-sampling. We start with an image of a certain size, 30x30 pixels (which are just values from 0 to 255) for example. From this full image, taking it as a matrix, we select a window of a certain size. Usually we choose a size that makes possible to divide the full image in little windows that do not collide with each other. In this case, from a image of 30x30 we are going to take a 3x3 window, leaving us a total of 100 windows. 

Now, in each window we are going to perform a "max-pooling", which is to take the highest value of the window and output it to a new "image" in the position where the window was in the previous image. After doing this to all windows, we obtain a new image or matrix of 10x10, smaller than the initial one, but also with a worse quality.

%%%%%% INCLUDE IMAGE EXPAINING POOLING %%%%%%
image explaining pooling

Convolutional layers, in the other hand, follow a proccess more complex. They apply convolution (hence the name of the network) to the input image, which can be defined in a simple way as mixing information from two sources according to a specific rule. From the mathematical point of view, convolution is the integral of the element-wise multiplication of the two input functions. While it is complex itself, it is usually used to simplify even more complex equations. In our case we are going to work only with integers, so the convolution used here is a \textit{discrete convolution}. 

\begin{equation}
	\label{discrete_conv}
	f*g(n) = \sum_{m= -\infty}^{\infty} f(m) g(n-m) 
\end{equation}

If we apply this to the algorithm of a \gls{cnn}, the first input function would be a part of the image itself, that is called \textit{receptive field} or \textit{window}; and the second would be the \textit{filter}, which is a matrix of weights of the same size of the window. The result of this convolution is a \textit{feature map}, a new image that shows how the feature recognised by the filter is distributed in the original picture. 

If the image is in color, it is composed by the three different channels of the RBG standard, so the multiplication has to be applied to all of them. This element-wise multiplication in matrices has the name of Hadamard Product and it produces a matrix of the same size of the inputs. Once the multiplication is done, we have three matrices that we sum in one value. Now a function $f$ is applied to this output to finally obtain the value of the first pixel of the feature map. After that, the window moves one pixel to the right (or to the first pixel of the next row, if the end is reached) and applies again convolution to obtain the next pixel of the feature map. 

\begin{figure}[!ht]
	\centering
	\includegraphics[width=\textwidth]{convolution.jpg}
	\caption{Convolution proccess for the creation of a Feature Map}
	\label{fig:convol_creation_feature_map}
\end{figure}

In the previous paragraph we said that a function $f$ is applied to the sum, as is usual in the structure of a neuron. Before \cite{krizhevsky2012deep}, the standard way to model this function was $f(x)=tanh(x)$. However, in this paper it is explained that these kind of saturating nonlinearities are much slower than a non-saturating nonlinearity as $f(x)=max(0, x)$. The neurons with this nonlinearity are called Rectified Linear Units or ReLUs, and help to train a deep convolutional network several times faster than their equivalents with $f(x)=tanh(x)$.

At this point, we know how convolution and pooling works. Two or three stages of convolution, followed by the non-linearity function, and then pooling; are stacked. After that, in the structure of a \gls{cnn} we find fully-connected layers, like a usual neural network, and finally an output layer that shows the prediction as the class with highest percenteage.

Backpropagation through a \gls{cnn} is as simple as through a regular deep network, allowing all the weights of the network (which also includes the filters of the convolution) to be trained.

\section{Face Detection}
The databases used in the training of the networks that perform the face recognition usually have face images already normalized  to  a  given  pose  standard. However,  the  conventional  input  image  of  computer  vision  systems  may  contain many items and/or faces, either for recognition or tracking. In these cases, face detection becomes mandatory. It acts as preprocessing of the images to determine first
if there is a face in the image, and second, where it is located (\cite{marques2010face}).

	\subsection{Limitations}
	Despite of the importance of the task, there are some limitations that strongly difficult it. First, any analysis that we perform on an image may be altered by the image’s resolution or noise. Such restricting factors can be mitigated by, for example, using a better quality equipment. However, other limitations to these techniques are even harder to overcome (\cite{yang2002detecting}):

	\begin{itemize}
		\item Pose. Face images may vary due to the relative position of the camera with respect to the face, resulting in a front, profile or even an inverted photo of the face.  
		\item Structural components. The presence or not of facial features such as moustaches and beards or accesories such as glasses may lead to not detect a face in the photo. Apart from the presence of the elements themselves, their wide diversity of shape, size and color also represent a limitation.  
		\item Facial expression. Certain facial expressions may distort a face so much that it cannot be detected.    
		\item Occlusion. The faces in the image may be partially covered by other objects or even other faces.
		\item Image orientation. Not only the portrait and landscape orientations, but also all the posible rotations that the image could have from what is expected in first place.
		\item Imaging conditions. In this section are included all factors that come from the construction of the photo, such as the illumination, for example.  
	\end{itemize}

	\subsection{Techniques}
	\label{subsec:face_detec_techniques}
	In order to perform the face detection in a photo, there are many different techniques among which to choose. In 1998, Henry A. Rowley and his team presented an approach based in the use of neural networks. In the Figure \ref{fig:rowley_network} we can see the algorithm followed to perfom the face detection on an image. Examining preprocessed small windows of a grayscaled image, a retinally connected network decides whether the window contains a face or not. The system arbitrates between multiple of these networks to improve the performance (\cite{rowley1998neural}). 

	\begin{figure}[!ht]
		\centering
		\includegraphics[width=13cm]{rowley_network.png}
		\caption{Basic algorithm used for face detection in \cite{rowley1998neural}}
		\label{fig:rowley_network}
	\end{figure}

	Another technique is presented in 2000 by Henry Schneiderman and Takeo Kanade for object detection, now using a statistical method (\cite{schneiderman2000statistical}). The inputs used here are still images, so to create visual attributes that are localized in space, frequency, and orientation, they needed to easily select information that is localized along these dimensions. The answer to this question was to perform a wavelet transform of the image. 

	Using a product of histograms, they represent the statistics of both object and "non-object" appearance. Each histogram represents the joint statistics of a subset of wavelet coefficients and their position on the object. Their approach was based in using many of these histograms in order to represent a wide variety of visual attributes. In the Figure \ref{fig:statistical_method_face_det} we can see how this method, in addition to detect the faces in the image, it also detects the direction to where the person is looking to.

	\begin{figure}[!ht]
		\centering
		\includegraphics[width=8cm]{fd_statistical_method.png}
		\caption{Results of applying the face detection method from \cite{schneiderman2000statistical}}
		\label{fig:statistical_method_face_det}
	\end{figure}

	Finally, in 2001, Paul Viola and Michael Jones presented a framework for fast object recognition (\cite{viola2001rapid}). Althought it could be trained to detect a wide variety of objects, the main objective always was the face detection. It stands out for performing a high detection rate with a very low false positive rate and capable to work in a real time situation, such as face detection in video.

	This method has a total of 4 stages:
	
	\begin{enumerate}
		\item Obtaining Haar features. In the Figure \ref{fig:haar_features} we can see the Haar filters that are used to extract face features (Haar features in short) in the OpenCV library. Haar features work with the similarities that all human faces share and that are shown in a photo as a difference in the intensities of the pixels. For example, in the Figure \ref{fig:application_haar_features} an horizontal line Haar feature is applied for detecting the position of the eyes, as the pixels that represent them are way darker than the pixels that represent the cheeks. The same happen with the vertical line Haar feature in the same figure, dectecting the dark pixels of the eyebrows and the brighter ones for the space in the middle. The use of Haar filters was motivated by the work of \cite{haar_features_before_vj}, but in this case they do not work directly with image intensities. 

		\begin{figure}[!ht]
			\centering
			\includegraphics[width=8cm]{types_haar_features.png}
			\caption{Different types of Haar features (\cite{opencv_haar_cascade_tut})}
			\label{fig:haar_features}
		\end{figure}

		\begin{figure}[!ht]
			\centering
			\includegraphics[width=8cm]{application_haar_features.png}
			\caption{Application of Haar features to an image (\cite{viola2001rapid})}
			\label{fig:application_haar_features}
		\end{figure}

		\item Analysis of the Haar features. The Haar features are computed very rapidly using an intermediate representation for the image called \textit{integral image} (also known as Summed Area Table (\cite{crow_summed_table})), obtaining the sum of all the values in the rectangular area of the feature. 

		\item Training with AdaBoost. A variant of the AdaBoost learning algorithm is used to select a small set of features, as the cost of using all features would be too high, and to train the classifier. A \textit{strong} classifier is built as a lineal combination of weak classifiers, which are focused in a single rectangle feature each. The objective of the training is to adjust the weights used in order to minimise false negatives. A \textit{weak} classifier $h_j(x)$ thus consist of a feature $f_j$, a threshold $\theta_j$ and a parity $p_j$ indicating the direction of the inequality sign:

		\begin{equation}
			\label{eq:viola_jones_weak_classifier}
			h_j(x)=
				\begin{cases}
			     	1 & \text{if $p_jf_j(x) < p_j\theta_j$} \\
			        0 & \text{otherwise} \\
				\end{cases}
		\end{equation}

		\item Cascade architecture. The main idea of this stage is to build a degenerated decission tree (called \textit{"cascade"} in the article) using strong classifiers like the one we can see in the Figure \ref{fig:cascade_decission_tree}. Image sub-windows are feeded to this cascade, so if a face is detected by the first classifier, it triggers the evaluation of the second classifier. A positive result in the sencond triggers a third classifier, and so on. If a face is not detected in one of the classifiers, the sub-window is rejected. 
		
		\begin{figure}[!ht]
			\centering
			\includegraphics[width=10cm]{cascade_decission_tree.png}
			\caption{Schematic depiction of a the detection cascade (\cite{viola2001rapid})}
			\label{fig:cascade_decission_tree}
		\end{figure}
			
	\end{enumerate}

\section{Public Data Sets} 
Face recognition is nothing but another kind of machine learning and as such, it needs to be feeded with data, face images in this case. The problem is that we need a high amount of them, in addition to that each face image has to be different (or the model would only work well with the data we worked with, and not any face, which is our purpose). As we cannot generate this dataset by ourselves, we must look for a public dataset with enough and different face images:

\begin{itemize}
	\item CASIA Webface Database. It is the second largest database of faces (first is private and belongs to Facebook), with more than 10,000 subjects and almost 500,000 images. In order to use it an agreement needs to be signed so the database will only be used for non-comercial, research or educational purposes. We finally discarded it because its size, which would be more suitable for a big project with a research group (\cite{casia_db}). 
	\item WIDER FACE. This database counts with more than 32,000 images and can be freely accessed by a Google or Baidu Drive. It has the advantage that its images are already labelled and the faces in them are marked. However, many of the images have more than one face on them (they say they count with almost 400,000 faces in the dataset) and we need them to have only one person (\cite{widerf_db}).
	\item \gls{lfw}. This database only counts with more than 13,000 images that only have one person in them, which is perfect for the scope of this project. It can be explored online and has been recently updated, solving some erratum. Finally, it also has the option to download the images aligned with funneling or commercial software, reducing the work to do on the dataset. Because of all these reasons, it is the dataset that is going to be used for the project (\cite{lfw_db}).
\end{itemize}

\section{Raspberry Pi}	
\label{sec:rasp_pi}
The Raspberry Pi was designed by scientists from the University of Cambridge and realeased their first commercial model in 2012. At the first instance it was thought to be a programming learning tool accessible for everyone thanks to the low cost of the device (\cite{raspberry_pi_for_learning}), now around the 40e (\cite{price_raspberry_pi}). However, a huge community has grown around this project that goes from the original purpose of programming learning to industrial and comercial products.

	\subsection{Specifications}
	All the specifications of this device can be found in the table \ref{table:rasp_pi_specs}. For this project a camera will be needed to take photos of the users. There are a lot of camera models available for the Raspberry Pi with no big differences of performance in the scope of this \gls{fyp}. However, the Camera Module V2 (8 Megapixels) was finally chosen above the rest because it is the official camera for the Raspberry and has been used in many other projects. It counts with a Sony Exmor IMX219 Sensor and it is capable to record up to 1080p at 30fps.

	\renewcommand{\arraystretch}{1.3}
	\begin{table}[h!b]
		\centering
	    \begin{tabular}{| C{3.5cm} | l |}
	    \hline
	    Model name & Raspberry Pi 3 Model B \\\hline
	    \multirow{2}{*}{Processor} & Chipset Broadcom BCM2387 \\ \cline{2-2}
                             	   & CPU Quad-Core 1,2GHz ARM Cortex-A53 \\\hline
		GPU & Dual Core Broadcom VideoCore IV \\\hline
		RAM memory & 1GB LPDDR2 \\\hline	    	    			
		\multirow{7}{*}[-3em]{Connectivity} & Ethernet socket 10/100Mbps BaseT \\ \cline{2-2}
                             	   & \makecell[tl]{BCM43438 chip, providing 802.11 b/g/n wireless \\ LAN and Bluetooth 4.1 (Classic and BLE)} \\ \cline{2-2}
                             	   & 4x USB ports 2.0 \\ \cline{2-2}
                             	   & 40-pin extended GPIO \\ \cline{2-2}
                             	   & \makecell[tl]{CSI-2 camera port for connecting a Raspberry \\ Pi camera (15 pins)} \\ \cline{2-2}
                             	   & \makecell[tl]{DSI display port for connecting a Raspberry \\ Pi touchscreen display (15 pins)} \\ \cline{2-2}
                             	   & \makecell[tl]{Micro-SD port for OS and storage (power \\ source up to 2.5A)} \\\hline
        \multirow{2}{*}{Video output} & Full size HDMI (rev 1.3 \& 1.4) \\ \cline{2-2}
                             	   & Composite RCA (PAL \& NTSC) \\\hline
        Audio output & 3.5mm jack conector \\\hline
	    \end{tabular}
	    \caption{Specifications of the Raspberry Pi 3 Model B}
	    \label{table:rasp_pi_specs}
	\end{table}
	\renewcommand{\arraystretch}{1}

%	\begin{itemize}
%		\item Model name: Raspberry Pi 3 Model B
%		\item Processor:
%			\begin{itemize}
%				\item Chipset Broadcom BCM2387.
%				\item CPU Quad-Core 1,2GHz ARM Cortex-A53.
%			\end{itemize}
%		\item GPU: Dual Core Broadcom VideoCore IV.
%		\item RAM memory: 1GB LPDDR2.
%		\item Conectivity:
%			\begin{itemize}
%				\item Ethernet socket 10/100Mbps BaseT.
%				\item BCM43438 chip, providing 802.11 b/g/n wireless LAN and Bluetooth 4.1 (Classic and BLE).
%				\item 4x USB ports 2.0.
%				\item 40-pin extended GPIO.
%				\item CSI-2 camera port for connecting a Raspberry Pi camera (15 pins).
%				\item DSI display port for connecting a Raspberry Pi touchscreen display (15 pins).
%				\item Micro-SD port for OS and storage (power source up to 2.5A).
%			\end{itemize}
%		\item Video output:
%			\begin{itemize}
%				\item Full size HDMI (rev 1.3 \& 1.4).
%				\item Composite RCA (PAL \& NTSC).
%			\end{itemize}
%		\item Audio output: 3.5mm jack conector.
%	\end{itemize}

	\subsection{Possible Operative System}
	In order to use the Raspberry Pi in this project, we first need to install an Operative System (OS). There are many possible options and, not a surprise, most of them are Linux-based:

	\begin{itemize}
		\item Raspbian. The official OS for Raspberry Pi based on the popular Debian distribution of Linux. Apart from the usual tools every OS provide to make the Raspberry run, Raspbian include more than 35.000 packages specifically optimised for this small machine (\cite{raspbian_main_website}). It has become the most popular OS for a general purpose project in the Raspberry. 
		\item Ubuntu Mate. Canonical, the maker of Ubuntu, released this version for the Raspberry Pi swapping out the Unity desktop interface for a lighter version called "Mate". It is bigger than Raspbian and will require a microSD card of 6GB or greater, which is recommended to be a Class 6 or Class 10 in order to avoid a bottleneck (\cite{ubuntu_mate_review}).
		\item ArchLinux ARM. It is the port of the desktop version of ArchLinux to the ARM architecture. The basic installation of this OS only comes with the Linux kernel, a shell and the package manager, so users must install all the packages they need manually (\cite{archlinux_arm_main_website}).
		\item Kali Linux. Another port from a desktop version OS to the ARM architecture, Kali Linux in this case. Like the desktop version, it is the distribution of choice for penetration testings and forensics analysis, as it comes with well-known tools for these purposes (\cite{kalilinux_website}).
		\item PiBang Linux. Insired by Crunchbang Linux, and based on Rasbian, it aims at being a fully functioning desktop. It features a modified version of Raspi-Config along with a fully optimized Openbox install (\cite{pibang_website}).
	\end{itemize} 

\section{Python}
\label{sec:python}
Some of the features of Python have been already commented in the Introduction of this report, but there is more to talk about. Some people say that in order to explain something well, you need to start from the root of the question. If we apply it to Python, we have to talk about the Zen of Python (\cite{origin_zen_of_python}, \cite{zen_of_python}), a collection of software principles that influenced the design of this language. A total of 20 principles (of which only 19 were written down) that show how Tim Peters, one of the open source development leaders of Python, wanted it to be beatiful, explicit, simple among other thigs.

The readability of Python was also in these principles and we can find many aspects of the language that confirm this feature. One that really impressed me at the first place was the lack of brackets ("\{\}"), which are the usual way to delimit control flow blocks in other languages. Instead of brackets, Python uses indentation. To indicate that a line is inside a function or an block (an \textit{if} block in the example), we just have to indent it one level deeper. We can see it clearly in the next comparative.

\noindent\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[caption=C code,frame=tlrb, language=C]{Name}
void foo(int x)
{
    if (x == 0) {
        bar();
    } else {
        foo2(x + 3);
    }
}
\end{lstlisting}
\end{minipage}\hfill
\begin{minipage}[t]{.45\textwidth}
\begin{lstlisting}[caption=Python code,frame=tlrb, language=Python]{Name}
def foo(x):
    if x == 0:
        bar()
    else:
        foo2(x + 3)
\end{lstlisting}
\end{minipage}

Another feature of Python is that it is interactive, which means that we do not need to write a Python program in a file to execute it later althought is also an option. Alternatively, we can interact with the prompt directly by executing the Python shell in the terminal. Also related with it, Python is interpreted, so it does not have to be compiled before executing (what happens to languages like C, C++ or Lisp). It is processed at runtime by the interpreter (\cite{python_overview}). 

Finally, the most important feature of Python: it is very easy to learn. It has fewer keywords than other languages, its strucure is much simpler and the syntax is can be easily understood with a certain level of English. 

These reasons have brought Python to be very popular. When looking at different sites, the ranking of the most popular languages can vary depending on the parameters that have been used for the calculations. The TIOBE Programming Community index in the Figure \ref{fig:tiobe_rank} shows a rank based in the hits for the search query, using engines like Google, Yahoo, or Wikipedia (\cite{tiobe_index_def}). The PYPL PopularitY is another rank that we can find in the Figure \ref{fig:pypl_rank}, which was created by analyzing how often language tutorials are searched on Google. The last one but not less important is the rank from the Github Octoverse, in the Figure \ref{fig:github_octoverse_rank}, which shows the number of pull request during 2017.

\begin{figure}[!ht]
	\centering
	\includegraphics[width=13cm]{TIOBE_python_ranking.png}
	\caption{TIOBE Index for April 2018 (\cite{tiobe_index})}
	\label{fig:tiobe_rank}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=9cm]{PYPL_python_ranking.png}
	\caption{PYPL PopularitY for March 2018 (\cite{pypl_pop_rank})}
	\label{fig:pypl_rank}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[width=13cm]{Github_python_ranking.png}
	\caption{Pull requests in Github for 2017 (\cite{octoverse_2017})}
	\label{fig:github_octoverse_rank}
\end{figure}

All rankings show the healthy condition in which Python is at the moment, being in the top 5 languages in all of them. second in two of them and fourth in the other one. It has even unseat Java as the second-most popular language in GitHub, with 40 percent more pull requests opened this year than last (\cite{octoverse_2017}). 